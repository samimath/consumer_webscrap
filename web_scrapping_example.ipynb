{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing reviews from webpages using webscraping tools and NLTK\n",
    "\n",
    "### Step 1 : Build webscraping tool\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"rvw js-rvw\" id=\"review-7157945\" data-id=\"7157945\" itemprop=\"reviews\" itemscope itemtype=\"http://schema.org/Review\"><div class=\"rvw__hdr\"><div class=\"rvw__hdr-stat\" itemtype=\"http://schema.org/Rating\" itemscope itemprop=\"reviewRating\"><meta itemprop=\"worstRating\" content=\"1\"><img data-rating=\"5.0\" src=\"//media.consumeraffairs.com/static/img/icons/stars/ca-stars-5.61b7b8c7580b.svg\" alt=\"Rated with 5 stars\" class=\"stars-rtg stars-rtg--sm\" /><meta itemprop=\"ratingValue\" content=\"5\"><meta itemprop=\"bestRating\" content=\"5\"></div></div><div class=\"rvw-aut\"><div class=\"rvw__pic rvw__pic--no-pic\"></div><div class=\"rvw-aut__inf\"><strong class=\"rvw-aut__inf-nm\" itemprop=\"author\">MARSHALL of Atlanta, GA</strong><strong class=\"rvw-aut__inf-ver\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_html(URL):\n",
    "\n",
    "    page = ''\n",
    "    while page == '':\n",
    "        try:\n",
    "            page = requests.get(url, verify=True)\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(5)\n",
    "            continue\n",
    "    return page\n",
    "\n",
    "class get_html_content:\n",
    "   \n",
    "    def __init__(self,URL):\n",
    "        \n",
    "        \n",
    "        self.page = requests.get(URL, verify=False)\n",
    "        \n",
    "        self.soup = BeautifulSoup(self.page.content, 'html.parser')\n",
    "        \n",
    "        self.meta = self.soup.find_all('meta')\n",
    "        \n",
    "        self.review_date = self.soup.find_all('span',attrs={'class':'ca-txt-cpt'})    \n",
    "        \n",
    "        self.review_auth = self.soup.find_all('div',attrs = {'class':'rvw-aut'})\n",
    "        \n",
    "        self.review_body = self.soup.find_all('div', class_='rvw-bd')\n",
    "        \n",
    "        self.rating_list = [[tag.attrs['content'],\\\n",
    "                        tag.attrs['itemprop']] \\\n",
    "                       for tag in self.meta if 'itemprop' in tag.attrs.keys() \\\n",
    "                       and tag.attrs['itemprop'].strip().lower() in ['ratingvalue'] ]\n",
    "        \n",
    "        if len(self.rating_list) == len(self.review_date):\n",
    "            \n",
    "            try:\n",
    "                self.rating_vals = [int(self.rating_list[i][0]) for i in range(0,len(self.rating_list))]\n",
    "            \n",
    "            except:\n",
    "                \n",
    "                self.rating_vals = [np.NaN for i in range(0,len(self.rating_list))]\n",
    "                \n",
    "        elif len(self.rating_list) < len(self.review_date):\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                val1 = [int(self.rating_list[i][0]) for i in range(0,len(self.rating_list))]\n",
    "                val2 = [np.NaN for i in range(len(self.rating_list),len(self.review_date))]\n",
    "                \n",
    "                self.rating_vals = val1+val2\n",
    "                \n",
    "            except:\n",
    "                \n",
    "                self.rating_vals = [np.NaN for i in range(0,len(self.review_date))]\n",
    "                \n",
    "\n",
    "\n",
    "class rm_html_tags():\n",
    "\n",
    "\n",
    "    def review_body(self,text):\n",
    "\n",
    "        clean1 = re.compile('<div.*?<p><p>')\n",
    "        \n",
    "        clean2 = re.compile('<.*?>')\n",
    "        \n",
    "        text1 = re.sub(clean1, '', str(text))   \n",
    "        \n",
    "        text2 = re.sub(clean2, '', str(text1))     \n",
    "        \n",
    "        return re.sub('\\s+',' ',str(text2)) \n",
    "    \n",
    "    def review_date(self,text):\n",
    "        \n",
    "        date_output = 'NA'\n",
    "        \n",
    "        clean1 = re.compile('<.*?>')\n",
    "        \n",
    "        text1 = re.sub(clean1, '', str(text)).upper()\n",
    "    \n",
    "        \n",
    "        if 'SEPT' in text1.upper():\n",
    "            \n",
    "            #print('correcting September dates')\n",
    "            \n",
    "            text1 = text1.upper().replace('SEPT','SEP')\n",
    "    \n",
    "        if \"ORIGINAL REVIEW: \" in text1:\n",
    "            \n",
    "           \n",
    "            text2 = text1.replace(\"ORIGINAL REVIEW: \",'')#.replace('SEPT','SEP')\n",
    "            \n",
    "        elif \"RESOLUTION RESPONSE: \" in text1:\n",
    "            \n",
    "            text2 = text1.replace(\"RESOLUTION RESPONSE: \",'')#.replace('SEPT','SEP')\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            text2 = text1\n",
    "\n",
    "        try:    \n",
    "            date_output = datetime.strptime(text2 , '%b. %d, %Y').strftime('%Y-%m-%d')\n",
    "            \n",
    "        except:\n",
    "            \n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            date_output = datetime.strptime(text2 , '%B %d, %Y').strftime('%Y-%m-%d')\n",
    "            \n",
    "        except:\n",
    "            \n",
    "            pass\n",
    "        \n",
    "        \n",
    "        return date_output\n",
    "    \n",
    "    def review_author(self,text):\n",
    "        \n",
    "        clean = re.compile('<.*?>')\n",
    "        \n",
    "        test_loc = re.sub(clean, '', str(text))  \n",
    "\n",
    "        \n",
    "        test_loc2 = test_loc.replace('\\n','').replace('  ','').replace('Verified Reviewer','')\n",
    "\n",
    "        test_loc2 = test_loc2.split(' of ')\n",
    "        \n",
    "        \n",
    "        if len(test_loc2) == 2:\n",
    "            \n",
    "            return test_loc2\n",
    "        \n",
    "        else:\n",
    "            test_loc2 = ['NA','NA']\n",
    "            \n",
    "        return test_loc2\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "def combine_review(URL):\n",
    "    \n",
    "    #page = None \n",
    "    output = pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        page = get_html_content(URL)\n",
    "        print('getting page content')\n",
    "        #print(page.content[0])\n",
    "    except: \n",
    "        page = None\n",
    "        print('page is None')\n",
    "        pass \n",
    "    \n",
    "    if page is None:\n",
    "        \n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        \n",
    "\n",
    "        content_class = rm_html_tags()\n",
    "\n",
    "        n = len(page.review_body)\n",
    "\n",
    "        for i in range(0,n):\n",
    "\n",
    "            auth_list = content_class.review_author(page.review_auth[i])\n",
    "            \n",
    "            review_list = content_class.review_body(page.review_body[i]) \n",
    "\n",
    "            date_list = content_class.review_date(page.review_date[i])\n",
    "\n",
    "            rating_list = page.rating_vals[i]\n",
    "\n",
    "            output = output.append(pd.DataFrame({'author':auth_list[0],'location':auth_list[1],'date':[date_list],'review':[review_list],'rating':[rating_list]}))\n",
    "\n",
    "    return output\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting page content\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "front_part = 'https://www.consumeraffairs.com/travel/southwest.html?page='\n",
    "\n",
    "end_part  = '#sort=top_reviews&filter=none'\n",
    "\n",
    "url_test = front_part +str(i)+ end_part\n",
    "#test = combine_review(url_test)\n",
    "\n",
    "test2 = combine_review(url_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.567324161529541\n"
     ]
    }
   ],
   "source": [
    "n1 = 0\n",
    "\n",
    "n2 = 20\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "page_list = pd.concat(Parallel(n_jobs = -1)(delayed(combine_review)(front_part +str(i)+ end_part) for i in range(n1,n2)))\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "min_date = page_list['date'].min()\n",
    "\n",
    "max_date = page_list['date'].max()\n",
    "\n",
    "page_list.to_csv('consumer_affairs_webscrap/consumer_affairs_webscraping_batch_'+str(n1)+'_'+str(n2-1)+'.csv',index = '')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i = 1\n",
    "front_part = 'https://www.consumeraffairs.com/travel/enterprise.html?page='\n",
    "\n",
    "end_part  = '#sort=top_reviews&filter=none'\n",
    "url_test = front_part + str(i)+end_part\n",
    "\n",
    "test_page = get_html_content(url_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "\n",
    "- How can we combine free text information to create a numerical score for each \n",
    "- Better survey design \n",
    "- How to account for different experiences in a customer's journey \n",
    "-- ques : causal inference, identify list of potential 'triggers' for each types of customers\n",
    "\n",
    "\n",
    "1) Obtain topics from raw text review data \n",
    "\n",
    "2) Design questions that align with the topics from 1)\n",
    "\n",
    "3) Create simple yes/no approach\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
